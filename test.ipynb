{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-17T01:24:15.663305Z",
     "start_time": "2025-07-17T01:24:04.130849Z"
    }
   },
   "source": [
    "from model import build_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from dataset import TranslationDataset\n",
    "from tokenizer_utils import TokenizerEnVi\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:24:18.187111Z",
     "start_time": "2025-07-17T01:24:17.944530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "with open(\"data/train.en.txt\", \"r\", encoding=\"utf-8\") as f_en, open(\"data/train.vi.txt\", \"r\", encoding=\"utf-8\") as f_vi:\n",
    "    en_sentences = [line.strip() for line in f_en]\n",
    "    vi_sentences = [line.strip() for line in f_vi]\n",
    "\n",
    "train_en, test_en, train_vi, test_vi = train_test_split (en_sentences, vi_sentences,\n",
    "                                                         test_size=0.2, shuffle=True, random_state=42)"
   ],
   "id": "d679d6b3178bd0c0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:24:20.294980Z",
     "start_time": "2025-07-17T01:24:20.287147Z"
    }
   },
   "cell_type": "code",
   "source": "len(en_sentences), len(vi_sentences)",
   "id": "3cd738b21b57a3aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133317, 133317)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:24:53.972668Z",
     "start_time": "2025-07-17T01:24:22.715657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pairs_train = list(zip(train_en, train_vi))\n",
    "pairs_test = list(zip(test_en, test_vi))\n",
    "\n",
    "vi_tokenizer = TokenizerEnVi(\"vi\")\n",
    "en_tokenizer = TokenizerEnVi(\"en\")\n",
    "\n",
    "vi_tokenizer.build_vocab(train_vi)\n",
    "en_tokenizer.build_vocab(train_en)\n",
    "\n",
    "pad_id = vi_tokenizer.word2idx[\"<pad>\"]\n",
    "\n",
    "\n",
    "train_dataset = TranslationDataset(pairs_train, en_tokenizer, vi_tokenizer, seq_len=30 )\n",
    "test_dataset = TranslationDataset(pairs_test, en_tokenizer, vi_tokenizer, seq_len=30 )\n",
    "import pickle\n",
    "\n",
    "with open(\"saved/en_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(en_tokenizer, f)\n",
    "with open(\"saved/vi_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vi_tokenizer, f)"
   ],
   "id": "85f6a777adbc31d8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T07:00:54.568691Z",
     "start_time": "2025-07-16T07:00:54.542621Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "84cea3da9f977796",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:04:22.109940Z",
     "start_time": "2025-07-15T20:04:22.102480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    encoder_input = torch.stack([item[\"encoder_input\"] for item in batch])\n",
    "    decoder_input = torch.stack([item[\"decoder_input\"] for item in batch])\n",
    "    encoder_mask = torch.stack([item[\"encoder_mask\"] for item in batch])\n",
    "    decoder_mask = torch.stack([item[\"decoder_mask\"] for item in batch])\n",
    "    label = torch.stack([item[\"label\"] for item in batch])\n",
    "\n",
    "    return {\n",
    "        \"encoder_input\": encoder_input,      # (batch_size, seq_len)\n",
    "        \"decoder_input\": decoder_input,      # (batch_size, seq_len)\n",
    "        \"encoder_mask\": encoder_mask,        # (batch_size, 1, 1, seq_len)\n",
    "        \"decoder_mask\": decoder_mask,        # (batch_size, 1, seq_len, seq_len)\n",
    "        \"label\": label                       # (batch_size, seq_len)\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "51286a95d3bd1974",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:30:58.179555Z",
     "start_time": "2025-07-17T01:30:58.175239Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(vi_tokenizer.word2idx))\n",
   "id": "c06625e981a530eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21169\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:04:25.227434Z",
     "start_time": "2025-07-15T20:04:22.175424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = build_transformer(\n",
    "    src_vocab_size=len(en_tokenizer.word2idx),\n",
    "    tgt_vocab_size=len(vi_tokenizer.word2idx),\n",
    "    src_seq_len=30,\n",
    "    tgt_seq_len=30,\n",
    "    d_model=512,\n",
    "    N=6,\n",
    "    h=8,\n",
    "    dropout=0.1,\n",
    "    d_ff=1024\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ],
   "id": "49710866f5c45b71",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:53:44.436530Z",
     "start_time": "2025-07-15T20:04:25.238017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epochs = 10\n",
    "best_val_loss = float(\"inf\")\n",
    "save_path     = \"saved/best_model.pth\"\n",
    "os.makedirs(\"saved\", exist_ok=True)\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"[Epoch {epoch}] Validating\"):\n",
    "        encoder_input = batch[\"encoder_input\"].to(device)\n",
    "        decoder_input = batch[\"decoder_input\"].to(device)\n",
    "        encoder_mask = batch[\"encoder_mask\"].to(device)\n",
    "        decoder_mask = batch[\"decoder_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # Forward\n",
    "        encoder_output = model.encode(encoder_input, encoder_mask)\n",
    "        decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
    "        output = model.project(decoder_output)\n",
    "\n",
    "        # Loss\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        labels = labels.view(-1)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            encoder_input = batch[\"encoder_input\"].to(device)\n",
    "            decoder_input = batch[\"decoder_input\"].to(device)\n",
    "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
    "            decoder_mask = batch[\"decoder_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
    "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
    "            output = model.project(decoder_output)\n",
    "\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Save model if best\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"✅ Saved best model.\")\n"
   ],
   "id": "95397d5fde29e668",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Validating:  48%|████▊     | 1585/3333 [49:18<54:23,  1.87s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      7\u001B[0m total_train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 9\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m[Epoch \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepoch\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m] Validating\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_input\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoder_input\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_input\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdecoder_input\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\myai\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[0;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[0;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\myai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    732\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 733\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    734\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    735\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    736\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    737\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    738\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    739\u001B[0m ):\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\myai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    787\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    788\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 789\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    790\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    791\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\myai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\pytorch-translate-en-vi\\dataset.py:41\u001B[0m, in \u001B[0;36mTranslationDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     37\u001B[0m src_mask \u001B[38;5;241m=\u001B[39m (torch\u001B[38;5;241m.\u001B[39mtensor(src_ids) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_id)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# (1,1,seq_len)\u001B[39;00m\n\u001B[0;32m     38\u001B[0m tgt_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_decoder_mask(tgt_input_ids)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_input\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_ids\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoder_input\u001B[39m\u001B[38;5;124m\"\u001B[39m: torch\u001B[38;5;241m.\u001B[39mtensor(tgt_input_ids),\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: src_mask\u001B[38;5;241m.\u001B[39mint(),\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoder_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: tgt_mask\u001B[38;5;241m.\u001B[39mint(),\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m: torch\u001B[38;5;241m.\u001B[39mtensor(tgt_label_ids),\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msrc_text\u001B[39m\u001B[38;5;124m\"\u001B[39m: src_text,\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtgt_text\u001B[39m\u001B[38;5;124m\"\u001B[39m: tgt_text,\n\u001B[0;32m     48\u001B[0m }\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
